{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exercise 4\n",
    "\n",
    "Work on this before the next lecture on 1 May. We will talk about questions, comments, and solutions during the exercise after the third lecture.\n",
    "\n",
    "Please do form study groups! When you do, make sure you can explain everything in your own words, do not simply copy&paste from others.\n",
    "\n",
    "The solutions to a lot of these problems can probably be found with Google. Please don't. You will not learn a lot by copy&pasting from the internet.\n",
    "\n",
    "If you want to get credit/examination on this course please upload your work to **your GitHub repository** for this course **before** the next lecture starts and post a link to your repository [in this thread](). If you worked on things together with others please add their names to the notebook so we can see who formed groups.\n",
    "\n",
    "---\n",
    "\n",
    "These are some useful default imports for plotting and [`numpy`](http://www.numpy.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pitfalls of estimating model performance\n",
    "\n",
    "This question sets up a classification problem to illustrate a common pitfall in\n",
    "evaluating model performance. To keep things simple the `y`s in this classroom problem\n",
    "are picked at random: there is no way for a classifier to learn how to model `y` based\n",
    "on the features provided. This means we know what the true accuracy is: 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "np.random.seed(6450345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A common task when building a new model is to select only those variables that are \"best\"\n",
    "for the problem. This selection procedure can take many different shapes, here we will\n",
    "compute the correlation of each feature with the target, select the 20 features that\n",
    "have the highest correlation and use those in our gradient boosted tree ensemble.\n",
    "\n",
    "We will then use cross validation to evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on each subset:\n",
      "[ 0.60349127  0.63092269  0.5975      0.63157895  0.65413534]\n",
      "Average score and uncertainty: (62.35 +- 0.924)%\n"
     ]
    }
   ],
   "source": [
    "def make_data(N=1000, n_vars=10,\n",
    "              n_classes=2):\n",
    "    X = np.random.normal(size=(N,n_vars))\n",
    "    y = np.random.choice(n_classes, N)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X,y = make_data(N=2000, n_vars=50000)\n",
    "\n",
    "select = SelectKBest(f_regression, k=20)\n",
    "X_sel = select.fit_transform(X, y)\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "scores = cross_val_score(clf, X_sel, y, cv=5, n_jobs=8)\n",
    "\n",
    "print(\"Scores on each subset:\")\n",
    "print(scores)\n",
    "avg = (100*np.mean(scores), 100*np.std(scores)/np.sqrt(scores.shape[0]))\n",
    "print(\"Average score and uncertainty: (%.2f +- %.3f)%%\" % avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What just happened? We have a classifier that achieves an accuracy of ~60% but we know that the features are uncorrelated with the target. How did this happen? What mistake did we make?\n",
    "\n",
    "What do we need to repair this? How do we know it is repaired? When the predicted performance\n",
    "is close to what we know to be the true performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is that to select the important features we used the whole data. And to evaluate the performance we didn't use the part of the data that was locked in a vault, but the same data we used to train our model. So to fix this, we are going to split our data into train and test set first, and then train on the train set and use test set only for the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on each subset:\n",
      "[ 0.64412811  0.60142349  0.56785714  0.67383513  0.68100358]\n",
      "Average score and uncertainty: (63.36 +- 1.932)%\n",
      "\n",
      "Score that we should actually use to estimate the performance:\n",
      "0.50\n"
     ]
    }
   ],
   "source": [
    "# your answer here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_data(N=2000, n_vars=50000)\n",
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, train_size=0.7)\n",
    "\n",
    "#use only train set to select the features\n",
    "select = SelectKBest(f_regression, k=20)\n",
    "select.fit(X_train, y_train)\n",
    "X_train = select.transform(X_train)\n",
    "# we transform X_test, but we don't use it till the final verification\n",
    "X_test = select.transform(X_test)\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5, n_jobs=8)\n",
    "\n",
    "print(\"Scores on each subset:\")\n",
    "print(scores)\n",
    "avg = (100*np.mean(scores), 100*np.std(scores)/np.sqrt(scores.shape[0]))\n",
    "print(\"Average score and uncertainty: (%.2f +- %.3f)%%\" % avg)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(\"\\nScore that we should actually use to estimate the performance:\")\n",
    "print(\"%.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we see that the score is indeed around 0.5. We can actually loop over the random_state to make sure, this is not a random down fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score 0.50 +- 0.001\n"
     ]
    }
   ],
   "source": [
    "random_states = np.arange(0, 100)\n",
    "clf = GradientBoostingClassifier()\n",
    "accuracies = []\n",
    "for random_state in random_states:\n",
    "    clf = GradientBoostingClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "score_mean = np.mean(accuracies)\n",
    "score_std = np.std(accuracies)\n",
    "print(\"Final score %.2f +- %.3f\" % (score_mean, score_std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
